{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow for the calibration and the analysis of a population-average model \n",
    "\n",
    "1. Parameter estimation using Maximum Likelihood Estimation\n",
    "2. Calculation of Profile Likelihoods for each parameter\n",
    "3. MCMC sampling\n",
    "4. Sobol analysis\n",
    "\n",
    "The pypesto ecosystem (https://pypesto.readthedocs.io/en/latest/index.html) is used to perform parameter estimation, profile likelihoods and MCMC sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pypesto\n",
    "import pypesto.optimize as optimize\n",
    "import pypesto.profile as profile\n",
    "import pypesto.visualize as visualize\n",
    "import pypesto.sample as sample\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.integrate import solve_ivp\n",
    "from SALib.sample import saltelli\n",
    "from SALib.analyze import sobol\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pre-processed data\n",
    "\n",
    "continous mean and standart deviation of BGS2 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FSH_moving = pd.read_csv('DataPoints/FSH_rollingData.txt', header=None)\n",
    "E2_moving = pd.read_csv('DataPoints/E2_rollingData.txt', header=None)\n",
    "LH_moving = pd.read_csv('DataPoints/LH_rollingData.txt', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model, parameters, inital condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start value originate from a differential evolution test run\n",
    "P = {\"k_syn_FSH\": 49.49418845,\n",
    "    \"k_cl_FSH\": 0.10008877, \n",
    "    \"k_syn_E2\": 12.95594545,\n",
    "    \"k_cl_E2\": 0.10001612,\n",
    "    \"T_FSH_E2\": 2.86346153,\n",
    "    \"n_FSH_E2\": 5.20396759,\n",
    "    \"k_syn_LH\": 0.10001534,\n",
    "    \"k_cl_LH\": 0.53593832,\n",
    "    \"T_E2_LH\": 0.10587896,\n",
    "    \"n_E2_LH\": 2.19039377, \n",
    "    \"log_growth\": 0.37592248, \n",
    "    \"log_mid\": 19.83817588}\n",
    "\n",
    "y_data = [FSH_moving[1].values, E2_moving[1].values, LH_moving[1].values]\n",
    "t_data  = [FSH_moving[0].values, E2_moving[0].values, LH_moving[0].values]\n",
    "sigma_data = [FSH_moving[2].values, E2_moving[2].values, LH_moving[2].values]\n",
    "\n",
    "t_eval = np.concatenate((FSH_moving[0].values, E2_moving[0].values, LH_moving[0].values))\n",
    "t_eval = np.unique(t_eval)\n",
    "y0 = [y_data[0][0], y_data[1][0], y_data[2][0]] \n",
    "t_init = 7.5\n",
    "t_final = 11.5\n",
    "t_span = [t_init, t_final]\n",
    "\n",
    "def dy_dt(t, y):\n",
    "    \n",
    "    FSH, E2, LH = y\n",
    "    \n",
    "    dFSH = P['k_syn_FSH'] * (1/(1 + np.exp(-P['log_growth']*(t - P['log_mid'])))) - P['k_cl_FSH']*FSH\n",
    "    dE2 = P['k_syn_E2'] * ((FSH/P['T_FSH_E2'])**P['n_FSH_E2'])/(1+(FSH/P['T_FSH_E2'])**P['n_FSH_E2']) - P['k_cl_E2']*E2\n",
    "    dLH = P['k_syn_LH'] * (1/(1 + np.exp(-P['log_growth']*(t - P['log_mid'])))) * ((E2/P['T_E2_LH'])**P['n_E2_LH'])/(1+(E2/P['T_E2_LH'])**P['n_E2_LH']) - P['k_cl_LH']*LH\n",
    "\n",
    "    dydt = [dFSH, dE2, dLH]\n",
    "    return dydt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define likelihood function for MLE and MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Objective(sol_y, sol_t, y_data, t_data, sigma_data):\n",
    "\n",
    "    H = np.zeros(1)\n",
    "    \n",
    "    for j in range(np.shape(y_data)[0]):\n",
    "        for i in range(len(y_data[j])):\n",
    "            t_index = np.where(sol_t == t_data[j][i])\n",
    "            H[0] += (1/sigma_data[j][i]**2)*(y_data[j][i] - sol_y[j][t_index])**2\n",
    "    \n",
    "    return H\n",
    "\n",
    "def CalcObjective(x):\n",
    "    # x = [k_syn_FSH, k_cl_FSH, ...]\n",
    "    # args = [y_data, t_data]\n",
    "    P[\"k_syn_FSH\"] = x[0]\n",
    "    P[\"k_cl_FSH\"] = x[1]\n",
    "    P[\"k_syn_E2\"] = x[2]\n",
    "    P[\"k_cl_E2\"] = x[3]\n",
    "    P[\"T_FSH_E2\"] = x[4]\n",
    "    P[\"n_FSH_E2\"] = x[5]\n",
    "    P[\"k_syn_LH\"] = x[6]\n",
    "    P[\"k_cl_LH\"] = x[7]\n",
    "    P[\"T_E2_LH\"] = x[8]\n",
    "    P[\"n_E2_LH\"] = x[9]\n",
    "    P[\"log_growth\"] = x[10]\n",
    "    P[\"log_mid\"] = x[11]\n",
    "\n",
    "    sol = solve_ivp(dy_dt, t_span, y0, t_eval=t_eval)\n",
    "    \n",
    "    return float(Objective(sol.y, sol.t, y_data, t_data, sigma_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLE: multi-start optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set number of starts \n",
    "n_starts = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]Executing task 0.\n",
      "Final fval=90.9066, time=50.0834s, n_fval=2197.\n",
      "  0%|          | 1/500 [00:50<6:56:32, 50.09s/it]Executing task 1.\n",
      "Final fval=226.2890, time=39.6199s, n_fval=1170.\n",
      "  0%|          | 2/500 [01:29<6:04:37, 43.93s/it]Executing task 2.\n",
      "Final fval=44.0647, time=76.4362s, n_fval=4511.\n",
      "  1%|          | 3/500 [02:46<8:06:51, 58.78s/it]Executing task 3.\n",
      "Final fval=861.1349, time=24.6332s, n_fval=728.\n",
      "  1%|          | 4/500 [03:10<6:14:29, 45.30s/it]Executing task 4.\n",
      "Final fval=8.2840, time=114.6796s, n_fval=9581.\n",
      "  1%|          | 5/500 [05:05<9:40:08, 70.32s/it]Executing task 5.\n",
      "Final fval=253.4396, time=17.4736s, n_fval=481.\n",
      "  1%|          | 6/500 [05:22<7:11:02, 52.35s/it]Executing task 6.\n",
      "Parameters obtained from history and optimizer do not match: [3.23742265e+01 1.00000000e-07 1.13054902e+02 6.08534978e+01\n",
      " 1.03001155e-03 3.25213254e+00 3.09812623e+01 1.00000000e-03\n",
      " 8.72271581e+00 3.23135700e+00 3.46376463e+00 2.11679379e+01], [3.23742265e+01 1.00000000e-07 1.13055473e+02 6.08538062e+01\n",
      " 1.03144771e-03 3.25187601e+00 3.09812623e+01 1.00000000e-03\n",
      " 8.72271581e+00 3.23135700e+00 3.46376463e+00 2.11679379e+01]\n",
      "Final fval=253.3910, time=28.8824s, n_fval=1066.\n",
      "  1%|▏         | 7/500 [05:51<6:07:07, 44.68s/it]Executing task 7.\n"
     ]
    }
   ],
   "source": [
    "custom_objective = pypesto.Objective(fun=CalcObjective, grad='3-point')\n",
    "\n",
    "lb = np.array([0.001, 0.0000001, 0.001, 0.0000001, 0.001, 1.0, 0.001, 0.001, 0.001, 1.0, 0.001, 5.0])\n",
    "ub = np.array([150.0, 150.0, 150.0, 150.0, 20.0, 5.0, 150.0, 150.0, 10.0, 5.0, 10.0, 25.0])\n",
    "\n",
    "problem = pypesto.Problem(objective=custom_objective, lb=lb, ub=ub)\n",
    "optimizer = optimize.ScipyOptimizer(method='L-BFGS-B')\n",
    "\n",
    "history_options = pypesto.HistoryOptions(trace_record=True)\n",
    "\n",
    "result = optimize.minimize(problem=problem,optimizer=optimizer,n_starts=n_starts,\n",
    "                              history_options=history_options,filename=None,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert optimisation results in data frame and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_optiresults = result.optimize_result.as_dataframe([\"x\",\"fval\",\"time\", \"grad\", \"x0\", \"exitflag\"])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "\n",
    "ax.plot(df_optiresults['fval'], 'x', color='grey', alpha=0.5)\n",
    "plt.yscale(\"log\")\n",
    "ax.xaxis.set_tick_params(which='major', size=10, width=2, direction='out')\n",
    "ax.yaxis.set_tick_params(which='major', size=10, width=2, direction='out')\n",
    "ax.yaxis.set_tick_params(which='minor', size=5, width=2, direction='out')\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.set(xlabel='run index (sorted by likelihood)', ylabel='- log$\\mathcal{L}(\\hat \\\\theta)$')\n",
    "\n",
    "P['k_syn_FSH'] = df_optiresults.x[0][0]\n",
    "P['k_cl_FSH'] = df_optiresults.x[0][1]\n",
    "P[\"k_syn_E2\"] = df_optiresults.x[0][2]\n",
    "P[\"k_cl_E2\"] = df_optiresults.x[0][3]\n",
    "P[\"T_FSH_E2\"] = df_optiresults.x[0][4]\n",
    "P[\"n_FSH_E2\"] = df_optiresults.x[0][5]\n",
    "P[\"k_syn_LH\"] = df_optiresults.x[0][6]\n",
    "P[\"k_cl_LH\"] = df_optiresults.x[0][7]\n",
    "P[\"T_E2_LH\"] = df_optiresults.x[0][8]\n",
    "P[\"n_E2_LH\"] = df_optiresults.x[0][9]\n",
    "P[\"log_growth\"] = df_optiresults.x[0][10]\n",
    "P[\"log_mid\"] = df_optiresults.x[0][11]\n",
    "sol = solve_ivp(dy_dt, t_span, y0, t_eval=t_eval)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15, 5))\n",
    "ax[0].scatter(t_data[0], y_data[0], color='#e0ca3cff', alpha=0.1)\n",
    "#ax[0].scatter(FSH_all[0], FSH_all[1], color='grey', alpha=0.3, marker='x')\n",
    "ax[0].errorbar(t_data[0][::10], y_data[0][::10], yerr=sigma_data[0][::10], color='#e0ca3cff', fmt=\"o\")\n",
    "ax[0].plot(sol.t, sol.y[0], color='#5d80c0ff', lw=3)\n",
    "ax[0].set_xlim(7.5, 11.25)\n",
    "ax[0].set_ylim(0.0, 8.5)\n",
    "\n",
    "ax[1].scatter(t_data[1], y_data[1], color='#e0ca3cff', alpha=0.1)\n",
    "#ax[1].scatter(E2_all[0], E2_all[1], color='grey', alpha=0.3, marker='x')\n",
    "ax[1].errorbar(t_data[1][::10], y_data[1][::10], yerr=sigma_data[1][::10], color='#e0ca3cff', fmt=\"o\")\n",
    "ax[1].plot(sol.t, sol.y[1], color='#5d80c0ff', lw=3)\n",
    "ax[1].set_xlim(7.5, 11.25)\n",
    "ax[1].set_ylim(0.0, 8.5)\n",
    "\n",
    "ax[2].scatter(t_data[2], y_data[2], color='#e0ca3cff', alpha=0.1)\n",
    "#ax[2].scatter(LH_all[0], LH_all[1], color='grey', alpha=0.3, marker='x')\n",
    "ax[2].errorbar(t_data[2][::10], y_data[2][::10], yerr=sigma_data[2][::10], color='#e0ca3cff', fmt=\"o\")\n",
    "ax[2].plot(sol.t, sol.y[2], color='#5d80c0ff', lw=3)\n",
    "ax[2].set_xlim(7.5, 11.25)\n",
    "ax[2].set_ylim(0.0, 3.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate and plot Profile Likelihoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = profile.parameter_profile(problem=problem, result=result, optimizer=optimizer, filename=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = visualize.profiles(result,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MCMC sampling \n",
    "-> decreasing the number of starts (n_start) will decrease the run time, but also effect the optimisation outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples =100000\n",
    "\n",
    "P = {\"k_syn_FSH\": df_optiresults['x'][0][0],\n",
    "     \"k_cl_FSH\": df_optiresults['x'][0][1],\n",
    "     \"k_syn_E2\": df_optiresults['x'][0][2],\n",
    "     \"k_cl_E2\": df_optiresults['x'][0][3],\n",
    "     \"T_FSH_E2\": df_optiresults['x'][0][4],\n",
    "     \"n_FSH_E2\": df_optiresults['x'][0][5],\n",
    "     \"k_syn_LH\": df_optiresults['x'][0][6],\n",
    "     \"k_cl_LH\": df_optiresults['x'][0][7],\n",
    "     \"T_E2_LH\": df_optiresults['x'][0][8],\n",
    "     \"n_E2_LH\": df_optiresults['x'][0][9],\n",
    "     \"log_growth\": df_optiresults['x'][0][10], \n",
    "     \"log_mid\": df_optiresults['x'][0][11]}\n",
    "\n",
    "lb = np.array([0.000000001, 0.000000001, 0.000000001, 0.000000001, 0.00000001, 0.00000001, 0.000000001, 0.000000001\n",
    "              , 0.000000001, 0.000000001, 0.000000001, 0.000000001])\n",
    "ub = np.array([150.0, 10.0, 150.0, 10.0, 50.0, 10.0, 150.0, 10.0, 50.0, 10.0, 10.0, 50.0])\n",
    "\n",
    "params = np.array(list(P.values()))\n",
    "\n",
    "sampler = sample.AdaptiveParallelTemperingSampler(internal_sampler=sample.AdaptiveMetropolisSampler(), n_chains=3)\n",
    "result = sample.sample(problem, n_samples=num_samples, sampler=sampler, x0=params, filename=None)\n",
    "\n",
    "ax = visualize.sampling_parameter_traces(result, use_problem_bounds=False, size=(25, 15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sobol Analysis \n",
    "create problem for Sobol analysis (https://salib.readthedocs.io/en/latest/getting-started.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dy_dt(t, y, k_syn_FSH, k_cl_FSH, k_syn_E2, k_cl_E2, T_FSH_E2, n_FSH_E2, \n",
    "          k_syn_LH, k_cl_LH, T_E2_LH, n_E2_LH, sig_growth, sig_midpoint):\n",
    "\n",
    "    FSH, E2, LH = y\n",
    "    \n",
    "    dFSH = k_syn_FSH * (1/(1+np.exp(-sig_growth*(t-sig_midpoint)))) - k_cl_FSH*FSH\n",
    "    dE2 = k_syn_E2 * ((FSH/T_FSH_E2)**n_FSH_E2)/(1+(FSH/T_FSH_E2)**n_FSH_E2) - k_cl_E2*E2\n",
    "    dLH = k_syn_LH * (1/(1+np.exp(-sig_growth*(t-sig_midpoint)))) * ((E2/T_E2_LH)**n_E2_LH)/(1+(E2/T_E2_LH)**n_E2_LH) - k_cl_LH*LH\n",
    "\n",
    "    dydt = [dFSH, dE2, dLH]\n",
    "    return dydt\n",
    "\n",
    "k_syn_FSH = df_optiresults['x'][0][0]\n",
    "k_cl_FSH = df_optiresults['x'][0][1]\n",
    "k_syn_E2 = df_optiresults['x'][0][2]\n",
    "k_cl_E2 = df_optiresults['x'][0][3]\n",
    "T_FSH_E2 = df_optiresults['x'][0][4]\n",
    "n_FSH_E2 = df_optiresults['x'][0][5]\n",
    "k_syn_LH = df_optiresults['x'][0][6]\n",
    "k_cl_LH = df_optiresults['x'][0][7]\n",
    "T_E2_LH = df_optiresults['x'][0][8]\n",
    "n_E2_LH = df_optiresults['x'][0][9]\n",
    "sig_growth = df_optiresults['x'][0][10]\n",
    "sig_midpoint = df_optiresults['x'][0][11]\n",
    "\n",
    "problem = {\n",
    "  'num_vars': 15, \n",
    "  'names': ['k_syn_FSH', 'k_cl_FSH', 'k_syn_E2', 'k_cl_E2', 'T_FSH_E2', 'n_FSH_E2',\n",
    "            'k_syn_LH', 'k_cl_LH', 'T_LH_E2', 'n_E2_LH', 'sig_growth','sig_midpoint', \n",
    "            'x1_0', 'x2_0', 'x3_0'],\n",
    "  'bounds':  np.column_stack((np.array([k_syn_FSH, k_cl_FSH, k_syn_E2, k_cl_E2, T_FSH_E2, \n",
    "                                        n_FSH_E2,k_syn_LH, k_cl_LH, T_E2_LH, n_E2_LH, sig_growth,sig_midpoint,\n",
    "                                        y0[0], y0[1],y0[2]])*0.8,\n",
    "                              np.array([k_syn_FSH, k_cl_FSH, k_syn_E2, k_cl_E2, T_FSH_E2, \n",
    "                                        n_FSH_E2, k_syn_LH, k_cl_LH, T_E2_LH, n_E2_LH, sig_growth,sig_midpoint,\n",
    "                                        y0[0], y0[1], y0[2]])*1.2))\n",
    "}\n",
    "\n",
    "# Generate samples\n",
    "##N should be a power of 2 value eg 512\n",
    "N=11\n",
    "vals = saltelli.sample(problem, 2**N, calc_second_order=False)\n",
    "\n",
    "# initializing matrix to store output\n",
    "Y = np.zeros((len(vals),3,len(t_eval)))\n",
    "\n",
    "# Run model (example)\n",
    "# numerically soves the ODE\n",
    "# output is X1, X2, and X3 at the end time step\n",
    "# could save output for all time steps if desired, but requires more memory\n",
    "\n",
    "for i in range(len(vals)):\n",
    "    sol = solve_ivp(dy_dt, t_span, [vals[i][12], vals[i][13], vals[i][14]], t_eval=t_eval, \n",
    "                    args=(vals[i][0], vals[i][1], vals[i][2], vals[i][3], vals[i][4], vals[i][5], \n",
    "                          vals[i][6], vals[i][7], vals[i][8], vals[i][9], vals[i][10], vals[i][11])).y\n",
    "    for k in range(len(t_eval)): \n",
    "        Y[i,0,k] = sol[0][k]\n",
    "        Y[i,1,k] = sol[1][k]\n",
    "        Y[i,2,k] = sol[2][k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Sobol index at each time point for each parameter and species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FSH_total = np.zeros((15,len(t_eval)))\n",
    "FSH_first = np.zeros((15,len(t_eval)))\n",
    "E2_total = np.zeros((15,len(t_eval)))\n",
    "E2_first = np.zeros((15,len(t_eval)))\n",
    "LH_total = np.zeros((15,len(t_eval)))\n",
    "LH_first = np.zeros((15,len(t_eval)))\n",
    "\n",
    "for k in range(len(t_eval)): \n",
    "    Si_FSH = sobol.analyze(problem, Y[:,0, k], calc_second_order=False, print_to_console=False)\n",
    "    Si_E2 = sobol.analyze(problem, Y[:,1, k], calc_second_order=False, print_to_console=False)\n",
    "    Si_LH = sobol.analyze(problem, Y[:,2, k], calc_second_order=False, print_to_console=False)\n",
    "    total, first = Si_FSH.to_df()\n",
    "    FSH_total[:,k] = total['ST']\n",
    "    FSH_first[:,k] = first['S1']\n",
    "    total, first = Si_E2.to_df()\n",
    "    E2_total[:,k] = total['ST']\n",
    "    E2_first[:,k] = first['S1']\n",
    "    total, first = Si_LH.to_df()\n",
    "    LH_total[:,k] = total['ST']\n",
    "    LH_first[:,k] = first['S1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot results as heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_keys = ['k_syn_FSH', 'k_cl_FSH', 'k_syn_E2', 'k_cl_E2', '$T_{FSH}^{E2}$', '$n_{FSH}^{E2}$',\n",
    "            'k_syn_LH', 'k_cl_LH', 'T_LH_E2', 'n_E2_LH', '$f_s$','$f_m$', \n",
    "            '$FSH_0$', '$E2_0$', '$LH_0$']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.heatmap(FSH_first[:, :2], yticklabels=param_keys)\n",
    "plt.show()\n",
    "ax = sns.heatmap(FSH_total[:, :2], yticklabels=param_keys)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.heatmap(E2_first[:, :2], yticklabels=param_keys)\n",
    "plt.show()\n",
    "ax = sns.heatmap(E2_total[:, :2], yticklabels=param_keys)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.heatmap(LH_first[:, :2], yticklabels=param_keys)\n",
    "plt.show()\n",
    "ax = sns.heatmap(LH_total[:, :2], yticklabels=param_keys)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
